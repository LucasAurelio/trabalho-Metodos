---
title: "Análise de Regressão"
author: "Jair Guedes, Lucas Aurelio, Rafaelle Amorim"
date: "13 de outubro de 2016"
output: html_document
---
```{r setup, include=FALSE, echo=FALSE}

library(ggplot2)
theme_set(theme_bw())
library(dplyr)
library(RcmdrMisc)

dados.sal.edu.exp <- readXL("11_dados_salario_educacao_experiencia.xlsx")

```

Nesse trabalho, iremos realizar uma <b>análise sobre um Modelo de Regressão Linear Múltipla(MRLM)</b>.
<br>
Os dados utilizados na construção do modelo possuem 3 variáveis:
<ul>
<li>Dependente/resposta: y.salario</li>
<li>Independente/fator: x1.educação</li>
<li>Independente/fator: x2.experiencia</li>
</ul>
<br><p>
Primeiro, vamos observar a distribuição dos dados para <i>x1.educacao</i> e <i>y.salario</i>:
```{r echo=FALSE}
ggplot(dados.sal.edu.exp, aes(x = x1.educacao, y = y.salario)) + labs(title="Dispersão Educação_x_Salário",x="Anos de Educação", y="Salário anual(milhares)")+
  geom_point()
```
</br>
Podemos observar que há um certo comportamento crescente para a distribuição entre as variáveis educação e salário. O que pode ser um indício da uma relação linear positiva.
</br>
Já para <i>x2.experiencia</i> e <i>y.salario</i>, temos:
```{r echo=FALSE}
ggplot(dados.sal.edu.exp, aes(x = x2.experiencia, y = y.salario))+labs(title="Dispersão Experiência_x_Salário",x="Anos de Experiência", y="Salário anual(milhares)")+ 
  geom_point()
```
</br>
Imediatamente percebemos que a relação entre essas duas variáveis é maior que a relação entre <i>x1.educacao</i> e <i>y.salario</i>, uma vez que se passada uma linha reta o mais próximo possível dos pontos (ideia de um modelo linear) as diferenças serão menores. Logo, há uma boa probabilidade de existir uma relação linear entre essas duas variáveis.
</br><p>
Agora, vamos analisar a correlação das variáveis.
</br>
Primeiro, temos que transformar o dados do dataframe em matrizes:
```{r}
#matriz com os valores de sálarios anuais
salario <- as.matrix(dados.sal.edu.exp$y.salario)
#matriz com os valores de anos de educação
educacao <- as.matrix(dados.sal.edu.exp$x1.educacao)
#matriz com os calores de anos de experiência
experiencia <- as.matrix(dados.sal.edu.exp$x2.experiencia)
```
Agora, com essas matrizes, podemos estimar os coeficientes de correlação entre as variáveis.
Assim, para a correlação entre <i>x1.educacao</i> e <i>y.salario</i>, temos:
```{r}
p.educacao.salario <- cor(salario,educacao)
p.educacao.salario
```
E para a correlação entre <i>x2.experiencia</i> e <i>y.salario</i>, temos:
```{r}
p.experiencia.salario <- cor(salario,experiencia)
p.experiencia.salario
```
Ambos os coeficientes de correlação são maiores que 0.9, o que indica uma correlação muito forte.
</br>
Assim, considerando como hipótese nula:
<ul>
<li>Ho: ρ = 0</li>
</ul>
para cada uma das correlações entre as variáveis, podemos realizar o teste de significância.
Primeiro para a correlação entre <i>x1.educacao</i> e <i>y.salario</i>:
```{r}
cor.test(dados.sal.edu.exp$y.salario,dados.sal.edu.exp$x1.educacao)
```
Agora para <i>x2.experiencia</i> e <i>y.salario</i>:
```{r}
cor.test(dados.sal.edu.exp$y.salario,dados.sal.edu.exp$x2.experiencia)
```
Assim, como os 'p-valor' dos testes são muito próximos de zero, rejeitamos Ho.
</b><p>
Nessa etapa do trabalho vamos estimar os valores de βi. Para isso, temos as matrizes:
```{r}
#matriz com os valores de salario
matrizY <- salario
matrizY
#matriz com os valores de anos de educação e anos de experiência
matrizX <- cbind(c(1,1,1,1,1),educacao,experiencia)
matrizX
```
Agora, estimamos os coeficientes.
```{r}
transX <- t(matrizX)
transXX <- transX%*%matrizX
invTransXX <- solve(transXX)
transXY <- transX%*%matrizY

matrizCoeficientes <- invTransXX%*%transXY
matrizCoeficientes
```
Logo, temos:
<ul>
<li>β0 = -23.75</li>
<li>β1 = -0.25</li>
<li>β2 = 5.5</li>
</ul>
</br><p>
Agora, a partir da matriz dos coeficientes que estimamos, e da matriz dos valores de Xi(<i>matrizX</i>), podemos obter a matriz de estimativas dos valores previstos:
```{r}
matrizYi <- matrizX%*%matrizCoeficientes
matrizYi
```
Assim, temos os valores acima como o vetor dos valores previstos.
</br><p>

Para calcular a Soma de Quadrados Total (SQtotal) temos que:
SQtotal = somatorio (Yi - media(Y))²
```{r}
Ysalario = mean(unlist(dados.sal.edu.exp["y.salario"]))
SQtotal = sum((unlist(dados.sal.edu.exp["y.salario"]) - Ysalario)**2)
SQtotal
```

Para calcular a Soma de Quadrados de Regressão (SQReg) temos que:
SQReg = somatorio(ˆYi - media(Y))²
```{r}
SQReg = sum((unlist(matrizYi) - Ysalario)**2)
SQReg
```

Para calcular o coeficiente de determinação R² = SQReg/SQtotal, temos que:
```{r}
RQuad = SQReg/SQtotal
RQuad
```

o R² de um modelo é  0.9944853, isto significa que 99.45% da variável dependente consegue ser explicada pelos regressores presentes no modelo.
</br><p>

(f)Realize uma ANOVA (Analise de Variancia) ao ńıvel de 5% de significancia e diga s estatisticamente significativo dizer que pelo menos uma das variaveis independentes exerce influencia sobre a variavel dependente/resposta y
Consideramos:
<ul>
<li>Ho:β0=β1=β2=0</li>
<li>H1: pelo menos um coeficiente é diferente de zero</li>
</ul>
Como primeiro passo da ANOVA, vamos encontrar o valor da distribuição F para <i>k</i>(grau de liberdade do numerador) e <i>n-k-1</i>(grau de liberdade do denominador):
```{r}
k <- 2
n <- 5
valueFtab <- qf(.95,k,n-k-1)
valueFtab
```
Agora, vamos calcular o F a partir das matrizes em questão. Temos que:
<ul>
<li>F = QMReg/QMRes</li>
</ul>
Como já temos o valor de SQReg (visto mais acima), só precisamos dividir pelo grau de liberdade para obtermos QMReg. Então, temos:
```{r}
QMReg <- SQReg/k
QMReg
```
E agora calculamos o valor de QMRes:
```{r}
SQRes <- t(matrizY)%*%matrizY - (t(matrizCoeficientes)%*%t(matrizX)%*%matrizY)
QMRes <- SQRes/(n-k-1)
QMRes
```
A partir desses dois valores, podemos calcular F:
```{r}
valorF <- QMReg/QMRes
valorF
```
Como o valor de F(=QMReg/QMRes) é bem maior que o valor da distribuição F para os graus de liberdade <i>k</i> e <i>n-k-1</i>, rejeitamos Ho. Ou seja, é  estatisticamente significativo dizer que pelo menos uma das variaveis independentes exerce influencia sobre a variavel resposta y.
</br><p>

(g)Realize testes marginais (t de Student) para testar individualmente se cada  variável independente exerce influência sobre a variável dependente y.

Utilizando a função t.test() do R, vamos verificar se a educação exerce influência sobre o salário e se a variável experiência exerce influência sobre o salário.
```{r}

t.test(salario,educacao, var.equal=FALSE, paired=FALSE)
t.test(salario, experiencia, var.equal=FALSE, paired=FALSE)
```
Como podemos ver o valor p para a relação entre salário e educação é igual a 0.001845 e para a relação salario e experiência é igual a 0.004889.O que indica uma influência das variáveis dependentes sobre a independente, pois os dois valores p encontrados são menores que 0.05.

(h) Diga qual é o salário anual estimado se um funcionário escolhido ao acaso tem 5 anos de educação após o ensino médio e 10 anos de experiência na empresa.
.
Temos que o salário previsto será igual a B0 + B1 * X1 + B2 * X2, realizando os cálculos temos que o salário previsto será igual a 30.
```{r}

salario.previsto <- -23.75 + 5*-0.25 + 10*5.50
salario.previsto
```


